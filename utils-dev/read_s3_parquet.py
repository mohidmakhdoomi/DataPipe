import boto3
import io
import pandas as pd
import argparse

# Read single parquet file from S3
def pd_read_s3_parquet(key, bucket, s3_client=None, **args):
    if s3_client is None:
        s3_client = boto3.client('s3')
    obj = s3_client.get_object(Bucket=bucket, Key=key)
    df_tmp = pd.read_parquet(io.BytesIO(obj['Body'].read()), **args)
    df_tmp[['hour', 'parquet']] = key.split('/')[-2:]
    df_tmp['s3_path'] = key
    return df_tmp

# Read multiple parquets from a folder on S3 generated by spark
def pd_read_s3_multiple_parquets(filepath, bucket, s3=None, 
                                 s3_client=None, verbose=False, **args):
    if not filepath.endswith('/'):
        filepath = filepath + '/'  # Add '/' to the end
    if s3_client is None:
        s3_client = boto3.client('s3')
    if s3 is None:
        s3 = boto3.resource('s3')
    s3_keys = [item.key for item in s3.Bucket(bucket).objects.filter(Prefix=filepath)
               if item.key.endswith('.parquet')]
    if not s3_keys:
        print('No parquet found in', bucket, filepath)
    elif verbose:
        print('Load parquets:')
        for p in s3_keys: 
            print(p)
    dfs = [pd_read_s3_parquet(key, bucket=bucket, s3_client=s3_client, **args) 
           for key in s3_keys]
    return pd.concat(dfs, ignore_index=True)

def main():
    parser = argparse.ArgumentParser(description='Query S3 Parquet files from data ingestion pipeline')
    parser.add_argument('--bucket', required=True, help='S3 bucket name')
    parser.add_argument('--folder', required=True, help='Base folder to look for parquet files recursively')
    
    args = parser.parse_args()
       
    try:
        # Configure pandas display options
        pd.set_option('display.max_columns', None)
        pd.set_option('display.width', None)
        pd.set_option('display.max_colwidth', 50)
        
        df = pd_read_s3_multiple_parquets(args.folder, args.bucket)
        assert df.sort_values(by=['id']).iloc[-1].equals(df.sort_values(by=['__source_lsn']).iloc[-1])
        print("First 50 rows")
        print(df.sort_values(by=['id']).head(50).to_string(index=False))
        print("Last 100 rows")
        print(df.sort_values(by=['id']).tail(50).to_string(index=False))
        print(f"Loaded {df.shape} total records")

    except Exception as e:
        print(f"Query failed: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())